{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkSA09sq_-o7",
        "outputId": "9e2f2aed-4993-4eb1-ed48-3b442569dc98"
      },
      "outputs": [],
      "source": [
        "!pip install ir-datasets\n",
        "import ir_datasets\n",
        "\n",
        "dataset = ir_datasets.load('cranfield')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_s06hg7AUT_",
        "outputId": "a41883fa-6a18-4ef1-9166-dcef253e5cc0"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [\n",
        "        lemmatizer.lemmatize(word)\n",
        "        for word in tokens\n",
        "        if word not in stop_words and word.isalpha()\n",
        "    ]\n",
        "    return tokens\n",
        "\n",
        "processed_docs = [' '.join(preprocess_text(doc.text)) for doc in dataset.docs_iter()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFpDA8q-AcRt"
      },
      "outputs": [],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "docs = [preprocess_text(doc.text) for doc in dataset.docs_iter()]\n",
        "bm25 = BM25Okapi(docs, k1=2, b=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "processed_queries = []\n",
        "query_ids = []\n",
        "for query in dataset.queries_iter():\n",
        "    processed_queries.append(' '.join(preprocess_text(query.text)))\n",
        "    query_ids.append(query.query_id)\n",
        "\n",
        "qrels_dict = {}\n",
        "for qrel in dataset.qrels_iter():\n",
        "    if qrel.relevance > 0:\n",
        "        qrels_dict.setdefault(qrel.query_id, set()).add(qrel.doc_id)\n",
        "\n",
        "doc_list = list(dataset.docs_iter())\n",
        "index_to_doc_id = [doc.doc_id for doc in doc_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_average_precision(ranked_doc_indices, relevant_doc_ids, doc_index_to_id):\n",
        "    hits = 0\n",
        "    sum_precisions = 0\n",
        "    num_relevant_retrieved = 0\n",
        "\n",
        "    for rank, doc_idx in enumerate(ranked_doc_indices):\n",
        "        doc_id = doc_index_to_id[doc_idx]\n",
        "        if doc_id in relevant_doc_ids:\n",
        "            hits += 1\n",
        "            num_relevant_retrieved += 1\n",
        "            precision_at_k = hits / (rank + 1)\n",
        "            sum_precisions += precision_at_k\n",
        "\n",
        "    return sum_precisions / len(relevant_doc_ids) if len(relevant_doc_ids) > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_results = {}\n",
        "for query_idx, query in enumerate(processed_queries):\n",
        "    query_id = query_ids[query_idx]\n",
        "    query_tokens = query.split()\n",
        "    scores = bm25.get_scores(query_tokens)\n",
        "    bm25_sorted_doc_indices = scores.argsort()[::-1]\n",
        "    bm25_results[query_id] = bm25_sorted_doc_indices\n",
        "\n",
        "total_bm25_avg_precision = 0\n",
        "num_queries_evaluated_bm25 = 0\n",
        "for query_id, ranked_doc_indices in bm25_results.items():\n",
        "    current_relevant_doc_ids = qrels_dict.get(query_id, set())\n",
        "    if not current_relevant_doc_ids:\n",
        "        continue\n",
        "\n",
        "    num_queries_evaluated_bm25 += 1\n",
        "    bm25_avg_precision = calculate_average_precision(ranked_doc_indices, current_relevant_doc_ids, index_to_doc_id)\n",
        "    total_bm25_avg_precision += bm25_avg_precision\n",
        "\n",
        "bm25_map_score = total_bm25_avg_precision / num_queries_evaluated_bm25 if num_queries_evaluated_bm25 > 0 else 0\n",
        "print(f\"BM25 Mean Average Precision (MAP): {bm25_map_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_interpolated_precision(ranked_doc_indices, relevant_doc_ids, doc_index_to_id, recall_levels):\n",
        "    \"\"\"Calculates interpolated precision at given recall levels for a single query.\"\"\"\n",
        "    precision_recall_points = []\n",
        "    hits = 0\n",
        "    num_relevant = len(relevant_doc_ids)\n",
        "    num_retrieved = 0\n",
        "\n",
        "    if num_relevant == 0:\n",
        "        return [0] * len(recall_levels)\n",
        "\n",
        "    for doc_idx in ranked_doc_indices:\n",
        "        num_retrieved += 1\n",
        "        doc_id = doc_index_to_id[doc_idx]\n",
        "        if doc_id in relevant_doc_ids:\n",
        "            hits += 1\n",
        "\n",
        "        current_precision = hits / num_retrieved\n",
        "        current_recall = hits / num_relevant\n",
        "        precision_recall_points.append((current_precision, current_recall))\n",
        "\n",
        "    precision_recall_points.insert(0, (0, 0))\n",
        "    if precision_recall_points[-1][1] < 1:\n",
        "         precision_recall_points.append((precision_recall_points[-1][0], 1.0))\n",
        "\n",
        "    precision_recall_points.sort(key=lambda x: x[1])\n",
        "    interpolated_precision = []\n",
        "    current_max_precision = 0\n",
        "\n",
        "    for i in range(len(precision_recall_points) - 1, -1, -1):\n",
        "         current_max_precision = max(current_max_precision, precision_recall_points[i][0])\n",
        "         interpolated_precision.insert(0, (current_max_precision, precision_recall_points[i][1]))\n",
        "\n",
        "    interpolated_precisions_at_levels = []\n",
        "    current_interpolated_idx = 0\n",
        "\n",
        "    for recall_level in recall_levels:\n",
        "        found_precision = 0.0\n",
        "        for prec, rec in interpolated_precision:\n",
        "             if rec >= recall_level:\n",
        "                  found_precision = prec\n",
        "                  break\n",
        "        interpolated_precisions_at_levels.append(found_precision)\n",
        "    return interpolated_precisions_at_levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm25_interpolated_precisions_per_query = []\n",
        "num_queries_for_11pt_eval_bm25 = 0\n",
        "\n",
        "for query_id, ranked_doc_indices in bm25_results.items():\n",
        "    current_relevant_doc_ids = qrels_dict.get(query_id, set())\n",
        "    if not current_relevant_doc_ids:\n",
        "        continue\n",
        "\n",
        "    num_queries_for_11pt_eval_bm25 += 1\n",
        "    interpolated_precisions = calculate_interpolated_precision(\n",
        "        ranked_doc_indices, current_relevant_doc_ids, doc_index_to_id, recall_levels_11pt\n",
        "    )\n",
        "    bm25_interpolated_precisions_per_query.append(interpolated_precisions)\n",
        "\n",
        "if num_queries_for_11pt_eval_bm25 > 0:\n",
        "    avg_bm25_interpolated_precision = np.mean(bm25_interpolated_precisions_per_query, axis=0)\n",
        "else:\n",
        "    avg_bm25_interpolated_precision = [0] * len(recall_levels_11pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_interpolated_f1(interpolated_precisions, rec):\n",
        "    interpolated_f1 = []\n",
        "    for p, r in zip(interpolated_precisions, rec):\n",
        "        if p + r == 0:\n",
        "            interpolated_f1.append(0.0)\n",
        "        else:\n",
        "            interpolated_f1.append(2 * p * r / (p + r))\n",
        "    return interpolated_f1\n",
        "\n",
        "avg_bm25_f1 = calculate_interpolated_f1(avg_bm25_interpolated_precision, avg_bm25_rec)\n",
        "avg_bm25_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_metrics_df = pd.DataFrame({\n",
        "    'interpolated_recalls_at_levels': avg_bm25_rec,\n",
        "    'interpolated_precisions_at_levels': avg_bm25_interpolated_precision,\n",
        "    'interpolated_f1_at_levels': avg_bm25_f1,\n",
        "})\n",
        "\n",
        "avg_metrics_df.to_csv('avg_bm25_metrics.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
